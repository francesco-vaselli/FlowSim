input_dim: 16 # Dimensionality of input (x)
context_dim: 6 # Dimensionality of context (y)
gpu: 0 # GPU to use
load_kwargs:
  # log_name: "affine_auto_big_15layer"
  # log_name: "dingo_new_data_bigger"
  log_name: "dingo_new_data"
  process: "dummy"
  cfm: true
  dnf: false
  # checkpoint: "checkpoint-latest.pt"
  # checkpoint: "dingo_new_data_bigger_@epoch_1000.pt"
  checkpoint: "dingo_new_data_@epoch_990.pt"
data_kwargs:
  dataset_path: "../data/gen-200kevents-1.2Mjets-manyVariables.npy"
  N_train: 500000 # Number of samples
  batch_size: 10000 # Batch size (increase to 4k for cfm)
  standardize: true # Standardize data
  physics_scaling: false # Scale data by physics intuition (broken?)
base_kwargs:
  cfm: # conditional flow matching
    sigma: 0.0001
    matching_type: "AlphaTTarget"
    ode_backend: "torchdiffeq" # ODE backend, choose from 'torchdiffeq' or 'torchdyn'
    alpha: 1
    timesteps: 100
    type: "resnet"
